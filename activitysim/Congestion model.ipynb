{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "center-pendant",
   "metadata": {},
   "source": [
    "# Congestion model\n",
    "\n",
    "This implements the congestion model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graduate-mitchell",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.ensemble\n",
    "import geopandas as gp\n",
    "from joblib import dump, load\n",
    "import openmatrix as omx\n",
    "import sklearn.inspection\n",
    "\n",
    "ESTIMATE = True  # When set to True, will estimate the random forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "talented-copying",
   "metadata": {},
   "outputs": [],
   "source": [
    "uber = pd.read_parquet('../data/uber_with_tracts.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "original-request",
   "metadata": {},
   "outputs": [],
   "source": [
    "uber = uber[~uber.congested_tt_ratio.isnull()].copy()  # some pairs had no overnight records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "north-validation",
   "metadata": {},
   "outputs": [],
   "source": [
    "uber.index = uber.index.rename(['from_geoid', 'to_geoid', 'hour'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worst-renaissance",
   "metadata": {},
   "source": [
    "## Load skims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innovative-terminal",
   "metadata": {},
   "outputs": [],
   "source": [
    "skims = omx.open_file('../la_abm/data/skims.omx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appropriate-information",
   "metadata": {},
   "outputs": [],
   "source": [
    "skim_idx = pd.read_parquet('../la_abm/data/skim_tracts.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acoustic-swaziland",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([[1, 2], [3, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grateful-ground",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_tt = pd.DataFrame(np.array(skims['car_freeflow']), columns=skim_idx.geoid, index=skim_idx.geoid).stack().rename('car_freeflow_tt')\n",
    "car_tt.index = car_tt.index.rename(['from_geoid', 'to_geoid'])\n",
    "\n",
    "netdist = pd.DataFrame(np.array(skims['car_distance_km']), columns=skim_idx.geoid, index=skim_idx.geoid).stack().rename('car_net_dist')\n",
    "netdist.index = netdist.index.rename(['from_geoid', 'to_geoid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decimal-thesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "uber = uber.join(car_tt, on=['from_geoid', 'to_geoid'], how='left')\n",
    "uber = uber.join(netdist, on=['from_geoid', 'to_geoid'], how='left')\n",
    "uber.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "positive-batman",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracts = gp.read_file('tract_centroids_density.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vulnerable-leather",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now see how well this works, if at all - might be too big \n",
    "along_route = pd.read_csv('../data/along_route.csv', dtype={'from_geoid': str, 'to_geoid': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proved-greek",
   "metadata": {},
   "outputs": [],
   "source": [
    "# along_route is only computed for one direction - do it for the other direction\n",
    "along_route_back = along_route.rename(columns={'from_geoid': 'to_geoid', 'to_geoid': 'from_geoid'})\n",
    "along_route = pd.concat([along_route, along_route_back], ignore_index=True)\n",
    "del along_route_back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungry-warrant",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(along_route)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weighted-video",
   "metadata": {},
   "outputs": [],
   "source": [
    "along_route = along_route.set_index(['from_geoid', 'to_geoid', 'band']).unstack().fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "black-aruba",
   "metadata": {},
   "outputs": [],
   "source": [
    "along_route.columns = [f'{col}_{band[1]}_{band[4]}' for col, band in along_route.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "federal-portal",
   "metadata": {},
   "outputs": [],
   "source": [
    "along_route = along_route.drop(columns=[i for i in along_route.columns if 'fromidx' in i or 'toidx' in i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "particular-shopper",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = uber.join(along_route.rename(columns='along_route_{}'.format), on=['from_geoid', 'to_geoid'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removed-conservation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO is this a reasonable amount of missing data?\n",
    "data.along_route_pop_dens_sqkm_25_0_2.isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beautiful-thursday",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fourth-metropolitan",
   "metadata": {},
   "outputs": [],
   "source": [
    "del along_route  # save memory, we'll need it for the RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expensive-brother",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge in origin and destination characteristics\n",
    "data = data.reset_index()\n",
    "\n",
    "data = data.merge(\n",
    "    tracts.drop(columns=['aland', 'total_pop', 'NAME', 'state', 'county', 'tract', 'tract_geoid', 'total_jobs', 'geometry'])\\\n",
    "        .rename(columns='from_{}'.format),\n",
    "    left_on='from_geoid',\n",
    "    right_on='from_GEOID',\n",
    "    how='left',\n",
    "    validate='m:1'\n",
    ")\n",
    "\n",
    "data = data.merge(\n",
    "    tracts.drop(columns=['aland', 'total_pop', 'NAME', 'state', 'county', 'tract', 'tract_geoid', 'total_jobs', 'geometry'])\\\n",
    "        .rename(columns='to_{}'.format),\n",
    "    left_on='to_geoid',\n",
    "    right_on='to_GEOID',\n",
    "    how='left',\n",
    "    validate='m:1'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considerable-cancer",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coral-poultry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This one geoid is missing data in tracts, just remove from estimation sample\n",
    "data = data[(data.to_geoid != '06037930401') & (data.from_geoid != '06037930401')].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neither-staff",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not data.to_job_dens_sqkm.isnull().any()\n",
    "assert not data.from_job_dens_sqkm.isnull().any()\n",
    "# okay for some bands to be null, no tracts in band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valid-arthur",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.fillna(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "streaming-average",
   "metadata": {},
   "source": [
    "## Fit random forest\n",
    "\n",
    "Split into test and training data, and fit the random forest. The training dataset is only 100,000 observations for tractability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contemporary-victor",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(seed=48923)\n",
    "train_test = np.full(len(data), False, dtype='bool')\n",
    "train_test[:100_000] = True\n",
    "rng.shuffle(train_test)\n",
    "data['train'] = train_test\n",
    "\n",
    "# it's possible that we could still overfit the model even looking at test set performance since congestion\n",
    "# is likely to be correlated across tracts\n",
    "excluded_tracts = set(tracts.sample(200, random_state=rng).GEOID)\n",
    "data.loc[data.from_geoid.isin(excluded_tracts) | data.to_geoid.isin(excluded_tracts), 'train'] = False\n",
    "\n",
    "np.argwhere(train_test)[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pointed-friday",
   "metadata": {},
   "outputs": [],
   "source": [
    "est_x = data.loc[data.train, ['hour', 'car_net_dist', 'car_freeflow_tt', *[i for i in data.columns if 'dens' in i]]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attempted-rapid",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ESTIMATE:\n",
    "    rf = sklearn.ensemble.RandomForestRegressor(n_estimators=100, min_samples_split=100, random_state=32013)\n",
    "    rf.fit(est_x, data[data.train].congested_tt_ratio)\n",
    "    dump((rf, est_x.columns.values), '../data/skim_rf.joblib')\n",
    "else:\n",
    "    rf, feature_names = load('../data/skim_rf.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "backed-brisbane",
   "metadata": {},
   "source": [
    "## Model fit and stats\n",
    "\n",
    "Out-of-bag prediction score, and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entire-minimum",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['predicted'] = rf.predict(data[est_x.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tamil-cooling",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = data.loc[~data.train]\n",
    "testr2 = 1 - ((test.congested_tt_ratio - test.predicted) ** 2).sum() / ((test.congested_tt_ratio - test.congested_tt_ratio.mean()) ** 2).sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advised-crisis",
   "metadata": {},
   "source": [
    "### Test $R^2$ on only tracts that were entirely excluded from model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "committed-couple",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tracts = data.loc[data.from_geoid.isin(excluded_tracts) | data.to_geoid.isin(excluded_tracts)]\n",
    "test_tract_r2 = 1 - ((test_tracts.congested_tt_ratio - test_tracts.predicted) ** 2).sum() / ((test_tracts.congested_tt_ratio - test_tracts.congested_tt_ratio.mean()) ** 2).sum()\n",
    "n_test_tracts = len(test_tracts.from_geoid.unique())\n",
    "test_tract_ss = len(test_tracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visible-satellite",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not sure the adj r2 makes sense here since it's a test score not a training score - no need to penalize for params\n",
    "print(f'''\n",
    "Test R^2: {testr2:.3f}\n",
    "Test R^2 on excluded tracts: {test_tract_r2:.3f}\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technical-destruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# permutation based feature importance, since \"Impurity-based feature importances can be misleading for high cardinality features (many unique values)\"\n",
    "# https://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html\n",
    "feature_importance = sklearn.inspection.permutation_importance(rf, est_x, data[data.train].congested_tt_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocational-recruitment",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', 300):\n",
    "    display(pd.Series(feature_importance['importances_mean'], index=est_x.columns).sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imposed-metro",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
