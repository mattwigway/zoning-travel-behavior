{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "mediterranean-tomorrow",
   "metadata": {},
   "source": [
    "# Population scenarios\n",
    "\n",
    "This creates the households and persons files used as input to ActivitySim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alleged-henry",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "SCENARIO = 'npv_low_opcost'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cenpy\n",
    "import geopandas as gp\n",
    "import io\n",
    "import sqlalchemy as sq\n",
    "import pyarrow.parquet as pq\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sudden-optics",
   "metadata": {},
   "source": [
    "## Get proportion of each property type in each PUMA that are in a particular tract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressive-guitar",
   "metadata": {},
   "outputs": [],
   "source": [
    "acs17 = cenpy.products.ACS(2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patient-speech",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert acs17.tables.loc['B25127'].description == 'TENURE BY YEAR STRUCTURE BUILT BY UNITS IN STRUCTURE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "average-purple",
   "metadata": {},
   "outputs": [],
   "source": [
    "counties = ['Los Angeles, CA', 'Orange, CA', 'Ventura, CA', 'Imperial, CA', 'Riverside, CA', 'San Bernardino, CA']\n",
    "\n",
    "tract_property_counts = pd.concat([acs17.from_county(county, variables='^B25127', level='tract') for county in counties])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressed-compact",
   "metadata": {},
   "source": [
    "### Summarize to PUMA level\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charged-minute",
   "metadata": {},
   "outputs": [],
   "source": [
    "tract_to_puma = pd.read_csv('../data/2010_Census_Tract_to_2010_PUMA.csv', dtype='str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brown-change",
   "metadata": {},
   "outputs": [],
   "source": [
    "tract_to_puma['tract_geoid'] = tract_to_puma.STATEFP.str.cat(tract_to_puma.COUNTYFP).str.cat(tract_to_puma.TRACTCE)\n",
    "tract_to_puma['puma_geoid'] = tract_to_puma.STATEFP.str.cat(tract_to_puma.PUMA5CE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sapphire-drain",
   "metadata": {},
   "outputs": [],
   "source": [
    "tract_property_counts = tract_property_counts.merge(\n",
    "    tract_to_puma[['tract_geoid', 'puma_geoid']],\n",
    "    left_on='GEOID',\n",
    "    right_on='tract_geoid',\n",
    "    how='left',\n",
    "    validate='1:1'\n",
    ")\n",
    "\n",
    "# one census tract, 06037137000, in Woodland Hills does not match, because it was accidentally\n",
    "# deleted in preparing geographies for the 2010 Census: https://www2.census.gov/geo/pdfs/reference/Geography_Notes.pdf\n",
    "# It's back in the latest ACS but not in the PUMA relationship file, and is split across two PUMAs (see below)\n",
    "assert not tract_property_counts[tract_property_counts.GEOID != '06037137000'].puma_geoid.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latter-transsexual",
   "metadata": {},
   "outputs": [],
   "source": [
    "pumas = gp.read_file('/Volumes/Pheasant Ridge/IPUMS/pumas/socal_pumas_projected.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italic-anniversary",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12, 8))\n",
    "pumas[\n",
    "    pumas.to_crs(epsg=4326).geometry.overlaps(tract_property_counts.loc[tract_property_counts.GEOID == '06037137000'].to_crs(epsg=4326).geometry.iloc[0])\n",
    "].to_crs(epsg=26943).plot(ax=ax, color=['pink', 'red'])\n",
    "tract_property_counts.loc[tract_property_counts.GEOID == '06037137000'].to_crs(epsg=26943).plot(ax=ax, color='blue', alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "searching-driver",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump for mapping in geojson.io\n",
    "overlap_pumas = pumas[\n",
    "        pumas.to_crs(epsg=4326).geometry.overlaps(tract_property_counts.loc[tract_property_counts.GEOID == '06037137000'].to_crs(epsg=4326).geometry.iloc[0])\n",
    "    ].to_crs(epsg=4326)[['geometry', 'PUMA']].reset_index()\n",
    "features = pd.concat([\n",
    "    overlap_pumas, \n",
    "    tract_property_counts.loc[tract_property_counts.GEOID == '06037137000', ['geometry', 'puma_geoid', 'tract_geoid']].to_crs(epsg=4326).reset_index()\n",
    "], ignore_index=True)\n",
    "\n",
    "features.to_file('broken_tract.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dried-excuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# looks like the tract in questions is split roughly evenly between the two PUMAs. Slice in half and put it in both\n",
    "split_tract = tract_property_counts[tract_property_counts.GEOID == '06037137000'].copy()\n",
    "split_tract[[i for i in split_tract.columns if i.startswith('B25127')]] /= 2\n",
    "split_tract = pd.concat([split_tract, split_tract], ignore_index=True)\n",
    "split_tract['puma_geoid'] = '06' + overlap_pumas.PUMA.to_numpy()\n",
    "assert not split_tract.puma_geoid.isnull().any()\n",
    "assert split_tract.puma_geoid.iloc[0] != split_tract.puma_geoid.iloc[1]\n",
    "tract_property_counts = pd.concat([\n",
    "    tract_property_counts[tract_property_counts.GEOID != '06037137000'],\n",
    "    split_tract\n",
    "], ignore_index=True)\n",
    "assert not tract_property_counts.puma_geoid.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worth-scotland",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_pumas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tender-incidence",
   "metadata": {},
   "source": [
    "### Summarize into the property type categories used in the modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "right-forward",
   "metadata": {},
   "outputs": [],
   "source": [
    "collabels = acs17.variables.loc[[i for i in split_tract.columns if i.startswith('B25127')]].label.str.split('!!', expand=True)[[2, 3, 4]].fillna('')\n",
    "with pd.option_context('display.max_colwidth', 200, 'display.max_rows', 500):\n",
    "    display(collabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automatic-mechanics",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfh_new_cols = [\n",
    "    'B25127_004E',  # owner occupied, 2010 or later\n",
    "    'B25127_011E',  # OO, 2000-2009\n",
    "    'B25127_047E',  # rented, 2010 or later\n",
    "    'B25127_054E'   # rented, 2000-2009\n",
    "]\n",
    "\n",
    "sfh_old_cols = [\n",
    "    'B25127_018E',  # owner occupied, 1980-1999\n",
    "    'B25127_025E',  # owner occupied, 1960-1979\n",
    "    'B25127_032E',  # owner occupied, 1940-1959\n",
    "    'B25127_039E',  # owner occupied, pre-1939\n",
    "    'B25127_061E',  # rented, 1980-1999\n",
    "    'B25127_068E',  # rented, 1960-1979\n",
    "    'B25127_075E',  # rented, 1940-1959\n",
    "    'B25127_082E'   # rented, 1939 or earlier\n",
    "]\n",
    "\n",
    "mfh_new_cols = [\n",
    "    'B25127_005E', # owner occ, 2010 or later, varying unit counts\n",
    "    'B25127_006E',\n",
    "    'B25127_007E',\n",
    "    'B25127_008E',\n",
    "    'B25127_012E', # owner occ, 2000-2009, varying unit counts\n",
    "    'B25127_013E',\n",
    "    'B25127_014E',\n",
    "    'B25127_015E',\n",
    "    'B25127_048E', # renter occ, 2010 or later, varying unit counts\n",
    "    'B25127_049E',\n",
    "    'B25127_050E',\n",
    "    'B25127_051E',\n",
    "    'B25127_055E', # renter occ, 2000-2009, varying unit counts\n",
    "    'B25127_056E',\n",
    "    'B25127_057E',\n",
    "    'B25127_058E'\n",
    "]\n",
    "\n",
    "mfh_old_cols = [\n",
    "    'B25127_019E', # owner occ, 1980-1999, varying unit counts\n",
    "    'B25127_020E',\n",
    "    'B25127_021E',\n",
    "    'B25127_022E',\n",
    "    'B25127_026E', # owner occ, 1960-1979, varying unit counts\n",
    "    'B25127_027E',\n",
    "    'B25127_028E',\n",
    "    'B25127_029E',\n",
    "    'B25127_033E', # owner occ, 1940-1959, varying unit counts\n",
    "    'B25127_034E',\n",
    "    'B25127_035E',\n",
    "    'B25127_036E',\n",
    "    'B25127_040E', # owner occ, 1939 or earlier, varying unit counts\n",
    "    'B25127_041E',\n",
    "    'B25127_042E',\n",
    "    'B25127_043E',\n",
    "    'B25127_062E', # renter occ, 1980-1999, varying unit counts\n",
    "    'B25127_063E',\n",
    "    'B25127_064E',\n",
    "    'B25127_065E',\n",
    "    'B25127_069E', # renter occ, 1960-1979, varying unit counts\n",
    "    'B25127_070E',\n",
    "    'B25127_071E',\n",
    "    'B25127_072E',\n",
    "    'B25127_076E', # renter occ, 1940-1959, varying unit counts\n",
    "    'B25127_077E',\n",
    "    'B25127_078E',\n",
    "    'B25127_079E',\n",
    "    'B25127_083E', # renter occ, 1939 or earlier, varying unit counts\n",
    "    'B25127_084E',\n",
    "    'B25127_085E',\n",
    "    'B25127_086E'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applied-northern",
   "metadata": {},
   "source": [
    "#### Sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "still-memphis",
   "metadata": {},
   "outputs": [],
   "source": [
    "collabels.loc[sfh_new_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loved-secretariat",
   "metadata": {},
   "outputs": [],
   "source": [
    "collabels.loc[sfh_old_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "needed-wilderness",
   "metadata": {},
   "outputs": [],
   "source": [
    "collabels.loc[mfh_new_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parallel-lover",
   "metadata": {},
   "outputs": [],
   "source": [
    "collabels.loc[mfh_old_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baking-partition",
   "metadata": {},
   "outputs": [],
   "source": [
    "tract_property_counts['sfh_new'] = tract_property_counts[sfh_new_cols].sum(axis=1)\n",
    "tract_property_counts['sfh_old'] = tract_property_counts[sfh_old_cols].sum(axis=1)\n",
    "tract_property_counts['mfh_new'] = tract_property_counts[mfh_new_cols].sum(axis=1)\n",
    "tract_property_counts['mfh_old'] = tract_property_counts[mfh_old_cols].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instrumental-lexington",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This should be close to but not exactly 1, and never more than 1, because we've excluded mobile homes, boats, rvs etc\n",
    "(\n",
    "    (tract_property_counts.sfh_new + tract_property_counts.sfh_old + tract_property_counts.mfh_new + tract_property_counts.mfh_old)\n",
    "    / tract_property_counts.B25127_001E\n",
    ").describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amber-jewelry",
   "metadata": {},
   "source": [
    "## Update with scenario\n",
    "\n",
    "This is where I will apply the tract level scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cultural-heritage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100% sample of ACS\n",
    "phys_housing_totals = ((\n",
    "    tract_property_counts.groupby(['puma_geoid', 'GEOID'])[['sfh_new', 'sfh_old', 'mfh_new', 'mfh_old']]\n",
    "        .sum()\n",
    "        .stack()).rename('n_hhs')\n",
    "    .round().astype('int').reset_index().rename(columns={'GEOID': 'tract_geoid'}))\n",
    "phys_housing_totals['puma'] = phys_housing_totals.puma_geoid.str.slice(2)\n",
    "phys_housing_totals['phys_housing'] = (phys_housing_totals.puma + '_').str.cat(phys_housing_totals.level_2.str.replace('sfh', 'SF').str.replace('mfh', 'MF'))\n",
    "phys_housing_totals['phys_housing_nopuma'] = phys_housing_totals.level_2.str.replace('sfh', 'SF').str.replace('mfh', 'MF')\n",
    "phys_housing_totals = phys_housing_totals.set_index('phys_housing')\n",
    "phys_housing_totals = phys_housing_totals.reset_index().drop(columns=['level_2', 'puma_geoid'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arbitrary-round",
   "metadata": {},
   "outputs": [],
   "source": [
    "phys_housing_totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "congressional-patio",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios = pd.read_parquet('../../construction/data/npv_tract_scenarios.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunrise-impression",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_chgs = scenarios[SCENARIO].copy().reset_index()\n",
    "scenario_chgs[['tract_geoid', 'phys_housing_nopuma']] = scenario_chgs['index'].str.slice(0, 18).str.split('_', 1, expand=True)\n",
    "scenario_chgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endangered-cutting",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_chgs.phys_housing_nopuma.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quick-laptop",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_chgs = scenario_chgs.groupby(['tract_geoid', 'phys_housing_nopuma'])[SCENARIO].sum()\n",
    "scenario_chgs.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resident-industry",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(scenario_chgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "official-planet",
   "metadata": {},
   "outputs": [],
   "source": [
    "12903 / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arbitrary-chemical",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this very special tract matches to *two* pumas... break housing change across pumas\n",
    "scenario_chgs.loc['06037137000'] /= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiovascular-representation",
   "metadata": {},
   "outputs": [],
   "source": [
    "phys_housing_totals = phys_housing_totals.merge(pd.DataFrame(scenario_chgs.rename('scenario')), left_on=['tract_geoid', 'phys_housing_nopuma'], right_index=True, how='left', validate='m:m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perfect-throw",
   "metadata": {},
   "outputs": [],
   "source": [
    "# okay for some to be null, no SF zoning in those locations perhaps (TODO figure this out)\n",
    "phys_housing_totals.scenario.isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weekly-transition",
   "metadata": {},
   "outputs": [],
   "source": [
    "phys_housing_totals['scenario'] = phys_housing_totals.scenario.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welsh-hierarchy",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_n_hhs = phys_housing_totals.n_hhs.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sized-inquiry",
   "metadata": {},
   "outputs": [],
   "source": [
    "phys_housing_totals['n_hhs'] += phys_housing_totals.scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "talented-phrase",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a handful of tracts have no ACS homes but do have homes in gp16 - patch up\n",
    "phys_housing_totals['n_hhs'] = np.maximum(phys_housing_totals.n_hhs, 0)\n",
    "# TODO scaling back not truly necessary here, but doing to match sorting model - should I?\n",
    "phys_housing_totals['n_hhs'] *= orig_n_hhs / phys_housing_totals.n_hhs.sum()\n",
    "phys_housing_totals['n_hhs'] = phys_housing_totals.n_hhs.round().astype('int64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civilian-driving",
   "metadata": {},
   "outputs": [],
   "source": [
    "phys_housing_totals.n_hhs.sum() - orig_n_hhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indian-clone",
   "metadata": {},
   "outputs": [],
   "source": [
    "phys_housing_totals.to_parquet(f'../data/{SCENARIO}_proportion_of_puma.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fancy-ranking",
   "metadata": {},
   "source": [
    "Now, move over to Julia to run the core of the algorithm!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
