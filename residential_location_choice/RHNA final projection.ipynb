{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RHNA projections\n",
    "\n",
    "We have three draft options for RHNA production, but they just give total unit numbers by jurisdiction—convert to PUMA-level single and multifamily amounts of construction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gp\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single/multifamily split by jurisdiction\n",
    "\n",
    "Figure out the single/multi-family split of new construction by jurisdiction, using Building Permits Survey info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bps = []\n",
    "for year in range(2010, 2019):\n",
    "    # d*$n census bureau and your arcane record layouts...\n",
    "    header = pd.read_csv(f'../data/permits/we{year}a.txt', header=None, nrows=1).iloc[0]\n",
    "    origHeader = header.copy()\n",
    "    header2 = pd.read_csv(f'../data/permits/we{year}a.txt', header=None, nrows=1, skiprows=1).iloc[0]\n",
    "    \n",
    "    for i in range(len(header)):\n",
    "        if isinstance(origHeader.loc[i], str) and 'unit' in origHeader.loc[i]:\n",
    "            #assert pd.isnull(header.iloc[i - 1])\n",
    "            #assert pd.isnull(header.iloc[i + 1])\n",
    "            header.loc[i - 1] = origHeader.loc[i]\n",
    "            header.loc[i + 1] = origHeader.loc[i]\n",
    "            \n",
    "    finalHeader = [f'{h1} {h2}'.strip() for h1, h2 in zip(header.fillna(''), header2.fillna(''))]\n",
    "    \n",
    "    data = pd.read_csv(f'../data/permits/we{year}a.txt', header=None, skiprows=2)\n",
    "    data.columns = finalHeader\n",
    "    bps.append(data)\n",
    "    \n",
    "bps = pd.concat(bps, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bps.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bps = bps[(bps['State Code'] == 6) & bps['County Code'].isin([25, 37, 59, 65, 71, 111])] # LA, OC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bps['Place Name'] = bps['Place Name'].str.replace(' town', '')\n",
    "production = bps.groupby('Place Name').agg({\n",
    "    '1-unit Units': np.sum,\n",
    "    '2-units Units': np.sum,\n",
    "    '3-4 units Units': np.sum,\n",
    "    '5+ units Units': np.sum,\n",
    "    '1-unit rep Units': np.sum,\n",
    "    '2-units rep Units': np.sum,\n",
    "    '3-4 units rep Units': np.sum,\n",
    "    '5+ units rep Units': np.sum,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "production['mf_production'] = production['2-units Units'] + production['3-4 units Units'] + production['5+ units Units']\n",
    "production['sf_production'] = production['1-unit Units']\n",
    "production['total_production'] = production.mf_production + production.sf_production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "production.index.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare reported and imputed numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for units in ['1-unit', '2-units', '3-4 units', '5+ units']:\n",
    "    production[f'{units} diff'] = production[f'{units} Units'] - production[f'{units} rep Units']\n",
    "    \n",
    "production[['1-unit diff', '2-units diff', '3-4 units diff', '5+ units diff']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute proportion multifamily of recent construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "production['proportionMultifamily'] = production.mf_production / production.total_production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "production.proportionMultifamily[production.proportionMultifamily.isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deal with cities that haven't produced any housing\n",
    "\n",
    "Laguna Woods is a bit of a surprise, but of course Vernon and City of Industry aren't. Fill these in with the values from the existing housing stock, from Census Reporter ACS numbers.\n",
    "\n",
    "Calipatria is not in the building permits database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "production.loc['Laguna Woods', 'proportionMultifamily'] = 0.66\n",
    "production.loc['Vernon', 'proportionMultifamily'] = 0.43\n",
    "production.loc['Industry', 'proportionMultifamily'] = 0.05 # actually census reporter reports 4 percent, but 12 percent in mobile homes, so recalculated with remaining units\n",
    "production.loc['Calipatria', 'proportionMultifamily'] = 0.27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not np.any(production.proportionMultifamily.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "production.rename(index={\n",
    "    'La Canada Flintridge': 'La Cañada Flintridge',\n",
    "    'San Buenaventura': 'San Buenaventura (Ventura)'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read SCAG RHNA options\n",
    "\n",
    "Thanks Paavo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latest version retrieved from here: https://twitter.com/calwatch/status/1192321136354197504\n",
    "rhna = pd.read_excel('../data/All Options Worksheet 11-06-19.xlsx', sheet_name='All Options')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhna[' city'] = rhna[' city'].replace({\n",
    "    'Eastvale City': 'Eastvale city',\n",
    "    'Jurupa Valley City': 'Jurupa Valley city'\n",
    "})\n",
    "rhna['city'] = rhna[' city'].str.replace(' city', '').str.replace(' town', '')\n",
    "\n",
    "rhna.rename(columns={\n",
    "    'Staff Option': 'opt_x',\n",
    "    'Option M': 'opt_m',\n",
    "    'Option H': 'opt_h',\n",
    "    'M Modified': 'opt_m_mod'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhna = rhna.merge(production, left_on='city', right_index=True, how='left', validate='1:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhna.city[rhna.proportionMultifamily.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read places: https://www.census.gov/cgi-bin/geo/shapefiles/index.php?year=2019&layergroup=Places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "places = gp.read_file('../data/places/tl_2019_06_place.shp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many ways can we mess up ñ?\n",
    "places['NAMELSAD'] = places.NAMELSAD.replace({\n",
    "    'La CaÃ±ada Flintridge city': 'La Cañada Flintridge city'\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "places = places.merge(rhna, left_on='NAMELSAD', right_on=' city', how='inner') # note space before city - it's a diff column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "placehu = pd.read_csv('../data/place_hu/place_hudata_with_overlays_2019-11-06T212431.csv', skiprows=[1])\n",
    "placehu_header = pd.read_csv('../data/place_hu/place_hudata_with_overlays_2019-11-06T212431.csv', header=None, nrows=2).transpose()\n",
    "with pd.option_context('display.max_colwidth', 200, 'display.max_rows', 600):\n",
    "    display(placehu_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "placehu['totalExistingSF'] = placehu.DP04_0007E + placehu.DP04_0008E\n",
    "placehu['totalExistingMF'] = placehu.DP04_0009E + placehu.DP04_0010E + placehu.DP04_0011E + placehu.DP04_0012E + placehu.DP04_0013E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "places['GEO_ID'] = '1600000US06' + places.PLACEFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "places = places.merge(placehu[['GEO_ID', 'totalExistingSF', 'totalExistingMF']], on='GEO_ID',\n",
    "                     how='left', validate='1:1')\n",
    "places['totalHousingUnits'] = places.totalExistingSF + places.totalExistingMF # ignores boats, RVs, mobile homes, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deal with unincorporated places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counties = gp.read_file('../data/counties/tl_2019_us_county.shp')\n",
    "counties = counties[(counties.STATEFP == '06') & counties.COUNTYFP.isin(['025', '037', '059', '065', '071', '111'])].to_crs(epsg=26943).set_index('COUNTYFP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so the strategy here is to read the county-level files, then subtract off the place-level files to get the unincorporated portion\n",
    "cobps = []\n",
    "for year in range(2010, 2019):\n",
    "    # d*$n census bureau and your arcane record layouts...\n",
    "    header = pd.read_csv(f'../data/permits/we{year}a.txt', header=None, nrows=1).iloc[0]\n",
    "    origHeader = header.copy()\n",
    "    header2 = pd.read_csv(f'../data/permits/we{year}a.txt', header=None, nrows=1, skiprows=1).iloc[0]\n",
    "    \n",
    "    for i in range(len(header)):\n",
    "        if isinstance(origHeader.loc[i], str) and 'unit' in origHeader.loc[i]:\n",
    "            #assert pd.isnull(header.iloc[i - 1])\n",
    "            #assert pd.isnull(header.iloc[i + 1])\n",
    "            header.loc[i - 1] = origHeader.loc[i]\n",
    "            header.loc[i + 1] = origHeader.loc[i]\n",
    "            \n",
    "    finalHeader = [f'{h1} {h2}'.strip() for h1, h2 in zip(header.fillna(''), header2.fillna(''))]\n",
    "    \n",
    "    data = pd.read_csv(f'../data/permits/we{year}a.txt', header=None, skiprows=2)\n",
    "    data.columns = finalHeader\n",
    "    cobps.append(data)\n",
    "    \n",
    "cobps = pd.concat(cobps, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cobps = cobps[(cobps['State Code'] == 6) & cobps['County Code'].isin([25, 37, 59, 65, 71, 111])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cotot = cobps[['County Code', '1-unit Units', '2-units Units', '3-4 units Units', '5+ units Units']].groupby('County Code').agg(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cotot['sf_production'] = cotot['1-unit Units']\n",
    "cotot['mf_production'] = cotot['2-units Units'] + cotot['3-4 units Units'] + cotot['5+ units Units']\n",
    "cotot['total_production'] = cotot.sf_production + cotot.mf_production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need existing housing stock to create growth rates\n",
    "county_housing = pd.read_csv('../data/county_housing/ACSDP5Y2017.DP04_data_with_overlays_2019-11-08T143350.csv', skiprows=[1])\n",
    "county_housing_idx = pd.read_csv('../data/county_housing/ACSDP5Y2017.DP04_data_with_overlays_2019-11-08T143350.csv', nrows=1).transpose()\n",
    "#county_housing_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_housing['totalExistingSF'] = county_housing.DP04_0007E + county_housing.DP04_0008E\n",
    "county_housing['totalExistingMF'] = county_housing.DP04_0009E + county_housing.DP04_0010E + county_housing.DP04_0011E + county_housing.DP04_0012E + county_housing.DP04_0013E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_housing['countyfips'] = county_housing.GEO_ID.str.slice(11).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cotot = cotot.merge(county_housing[['countyfips', 'totalExistingSF', 'totalExistingMF']], how='left', left_index=True, right_on='countyfips', validate='1:1').set_index('countyfips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cotot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subtract off incorporated places\n",
    "def findCounty (place):\n",
    "    intArea = counties.intersection(place.geometry).area\n",
    "    if np.any(intArea > 100):\n",
    "        return intArea.idxmax()\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "places['county'] = places.to_crs(epsg=26943).apply(findCounty, axis=1)\n",
    "places = places.dropna(subset=['county']) # get rid of places outside SCAG region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "places[['NAME', 'county']].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "places['countyint'] = places.county.astype('int64')\n",
    "coinc = places[['sf_production', 'mf_production', 'total_production', 'totalExistingSF', 'totalExistingMF', 'countyint']].groupby('countyint').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "couninc = cotot[['sf_production', 'mf_production', 'total_production', 'totalExistingSF', 'totalExistingMF']] - coinc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "couninc['proportionMultifamily'] = couninc.mf_production / couninc.total_production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "couninc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.all(couninc >= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the geometry for unincorporated places\n",
    "unincgeom = gp.overlay(counties, places.to_crs(epsg=26943), how='difference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unincgeom.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unincgeom.rename(index=int, inplace=True)\n",
    "unincgeom['proportionMultifamily'] = couninc.proportionMultifamily\n",
    "unincgeom['totalExistingSF'] = couninc.totalExistingSF\n",
    "unincgeom['totalExistingMF'] = couninc.totalExistingMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unincgeom.proportionMultifamily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unincgeom.loc[111, 'NAMELSAD'] = 'Unincorporated Ventura Co.'\n",
    "unincgeom.loc[37, 'NAMELSAD'] = 'Unincorporated Los Angeles Co.'\n",
    "unincgeom.loc[71, 'NAMELSAD'] = 'Unincorporated San Bernardino Co.'\n",
    "unincgeom.loc[65, 'NAMELSAD'] = 'Unincorporated Riverside Co. (incl. March JPA)'\n",
    "unincgeom.loc[59, 'NAMELSAD'] = 'Unincorporated Orange Co.'\n",
    "unincgeom.loc[25, 'NAMELSAD'] = 'Unincorporated Imperial Co.'\n",
    "unincgeom['NAME'] = unincgeom.NAMELSAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unincgeom = unincgeom.merge(rhna[['city', ' city', 'opt_x', 'opt_h', 'opt_m', 'opt_m_mod']], left_on='NAMELSAD', right_on='city', how='left', validate='1:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unincgeom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_places = pd.concat([places.to_crs(epsg=26943), unincgeom[['NAMELSAD', 'NAME', 'city', ' city', 'geometry', 'proportionMultifamily', 'totalExistingSF', 'totalExistingMF', 'opt_x', 'opt_h', 'opt_m', 'opt_m_mod']]], ignore_index=True, sort=True)\n",
    "all_places.crs = {'init': 'epsg:26943'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not all_places.NAMELSAD.duplicated().any() # there are some duplicates in the Census dataset, but they are not in LA/Orange County"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhna[' city'][~rhna[' city'].isin(all_places.NAMELSAD)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_places.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhna[' city'][~rhna[' city'].isin(all_places.NAMELSAD)] # Should just have NaN which is blank row in excel sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_places['opt_x_mf'] = all_places.opt_x * all_places.proportionMultifamily\n",
    "all_places['opt_h_mf'] = all_places.opt_h * all_places.proportionMultifamily\n",
    "all_places['opt_m_mf'] = all_places.opt_m * all_places.proportionMultifamily\n",
    "all_places['opt_m_mod_mf'] = all_places.opt_m_mod * all_places.proportionMultifamily\n",
    "\n",
    "all_places['opt_x_sf'] = all_places.opt_x * (1 - all_places.proportionMultifamily)\n",
    "all_places['opt_h_sf'] = all_places.opt_h * (1 - all_places.proportionMultifamily)\n",
    "all_places['opt_m_sf'] = all_places.opt_m * (1 - all_places.proportionMultifamily)\n",
    "all_places['opt_m_mod_sf'] = all_places.opt_m_mod * (1 - all_places.proportionMultifamily)\n",
    "\n",
    "all_places['opt_x_mf_growth'] = all_places.opt_x_mf / all_places.totalExistingMF\n",
    "all_places['opt_h_mf_growth'] = all_places.opt_h_mf / all_places.totalExistingMF\n",
    "all_places['opt_m_mf_growth'] = all_places.opt_m_mf / all_places.totalExistingMF\n",
    "all_places['opt_m_mod_mf_growth'] = all_places.opt_m_mod_mf / all_places.totalExistingMF\n",
    "\n",
    "all_places['opt_x_sf_growth'] = all_places.opt_x_sf / all_places.totalExistingSF\n",
    "all_places['opt_h_sf_growth'] = all_places.opt_h_sf / all_places.totalExistingSF\n",
    "all_places['opt_m_sf_growth'] = all_places.opt_m_sf / all_places.totalExistingSF\n",
    "all_places['opt_m_mod_sf_growth'] = all_places.opt_m_mod_sf / all_places.totalExistingSF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_places.loc[(all_places.totalExistingMF == 0) & (all_places.proportionMultifamily == 0), 'opt_x_mf_growth'] = 0\n",
    "all_places.loc[(all_places.totalExistingMF == 0) & (all_places.proportionMultifamily == 0), 'opt_h_mf_growth'] = 0\n",
    "all_places.loc[(all_places.totalExistingMF == 0) & (all_places.proportionMultifamily == 0), 'opt_m_mf_growth'] = 0\n",
    "all_places.loc[(all_places.totalExistingMF == 0) & (all_places.proportionMultifamily == 0), 'opt_m_mod_mf_growth'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump for qgis mapping\n",
    "all_places.to_file('../maps/places_with_rhna.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(2, 4, figsize=(36, 12))\n",
    "\n",
    "optnames = {\n",
    "    'x': 'Staff Option',\n",
    "    'h': 'Option H', \n",
    "    'm': 'Option M',\n",
    "    'm_mod': 'Coastal Option'\n",
    "}\n",
    "\n",
    "mfsfnames = {\n",
    "    'mf': 'Multifamily',\n",
    "    'sf': 'Single family'\n",
    "}\n",
    "\n",
    "for col, opt in enumerate(['x', 'h', 'm', 'm_mod']):\n",
    "    for row, mf in enumerate(['mf', 'sf']):\n",
    "        #plt.subplot(2, 4, row * 4 + col + 1)\n",
    "        all_places[f'opt_{opt}_{mf}_dens'] = np.log(all_places[f'opt_{opt}_{mf}'] / all_places.area * 1e6 + 1)\n",
    "        all_places.plot(column=f'opt_{opt}_{mf}_dens', legend=True, ax=ax[row, col])\n",
    "        ax[row, col].set_title(f'{optnames[opt]}, {mfsfnames[mf]}')\n",
    "        ax[row, col].set_xticks([])\n",
    "        ax[row, col].set_yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize to PUMA level\n",
    "\n",
    "Push down to tracts and summarize up weighting by housing in the tract, I was going to weight by SF/MF separately, but that assumes that all apartment will go where apartments are now, for example. Instead I just use a population weighted average from MABLE - which assumes infill development, but not a specific single-family/multifamily distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracts = gp.read_file('../data/tracts/tl_2019_06_tract.shp')\n",
    "tracts = tracts[tracts.COUNTYFP.isin(['025', '037', '059', '065', '071', '111'])].to_crs(epsg=26943)\n",
    "tracts.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tractCentroids = tracts.copy()\n",
    "tractCentroids['geometry'] = tracts.centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tractPlaces = gp.sjoin(tractCentroids, all_places.to_crs(epsg=26943), op='within')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tractPlaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tractPlaces.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tractHousing = pd.read_csv('../data/tract_housing/ACS_17_5YR_DP04_with_ann.csv', skiprows=[1], dtype={'GEO.id2': 'str'})\n",
    "tractHousingIdx = pd.read_csv('../data/tract_housing/ACS_17_5YR_DP04_with_ann.csv', nrows=1).transpose()\n",
    "tractHousingIdx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tractPlaces = tractPlaces.merge(tractHousing[['GEO.id2', 'HC01_VC03']].rename(columns={'HC01_VC03': 'tractTotalHsg'}), left_on='GEOID_left', right_on='GEO.id2', how='left', validate='1:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tractPumas = pd.read_csv('../data/mable_tracts_pumas.csv', skiprows=[1], dtype={'county': 'str', 'tract': 'str', 'puma12': 'str'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tractPumas['geoid'] = tractPumas.county.str.cat(tractPumas.tract.str.replace('.', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tractPlaces = tractPlaces.merge(tractPumas, left_on='GEOID_left', right_on='geoid', how='left', validate='1:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tractPlaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tractPlaces.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grpd = tractPlaces.groupby('puma12')\n",
    "pumaMfGrowth = pd.DataFrame({\n",
    "    k: grpd.apply(lambda df: np.average(df[k], weights=df.tractTotalHsg)) for k in tractPlaces.columns if k.endswith('mf_growth')\n",
    "}).rename(columns=lambda x: x.replace('_mf', ''))\n",
    "\n",
    "pumaSfGrowth = pd.DataFrame({\n",
    "    k: grpd.apply(lambda df: np.average(df[k], weights=df.tractTotalHsg)) for k in tractPlaces.columns if k.endswith('sf_growth')\n",
    "}).rename(columns=lambda x: x.replace('_sf', ''))\n",
    "\n",
    "pumaGrowth = pd.concat([pumaMfGrowth, pumaSfGrowth], keys=['mf', 'sf'], sort=True)\n",
    "pumaGrowth.index = [f'{puma}_{mfsf}' for mfsf, puma in pumaGrowth.index.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pumaGrowth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pumaGrowth.to_csv('../data/puma_growth.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(all_places.opt_m_mod_mf) + np.sum(all_places.opt_m_mod_sf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pumaGrowth.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
